# Introduction {#intro}

This book is about harnessing the power of modern computers to make the most of geographic data.
It teaches a range of spatial skills, including: reading, writing and manipulating geographic data; making static and interactive maps; and modeling geographic data.
By joining together various spatial operations in scripts and functions, the book also shows how these skills support a transparent and reproducible, i.e. scientific workflow.
Learning how to use existing tools is exciting.
However, it is even more liberating, if you can create new tools yourself.
By the end of the book you should be well-equipped enough to create new tools in the form of shareable R functions.

Over the last few decades a huge amount of work has gone into developing Free and Open Source Software for Geospatial Applications (FOSS4G).
This means that spatial data analysis is no longer the preserve of those who can afford expensive programs, and the hardware to run them.
Anyone can now download high performance spatial libraries on their computer.
However, despite the growth of geospatial software that is *open source*, much of it remains *inaccessible* to many potential users due to the required expert knowledge to handle it.

A major aim of this book is to make geographical data analysis more accessible.
R is a flexible language that allows access to many spatial software libraries (see section \@ref(why-geocomputation-with-r)).
Before going into the details of the software, however, it is worth taking a step back and thinking about what we mean by geocomputation.

## A definition of geocomputation, and why it is in the book's title

Geocomputation is a relatively young field with its [~30 year history dating back to the first [conference](http://www.geocomputation.org/) on the subject in 1996^[The conference took place at the University of Leeds where the concept for this book was dreamt up, and followed by a flurry of subsequent publications. However, algorithms published under the geocomputational banner have also influenced the direction of geographical research, as we will see in subsequent chapters.
<!-- todo: which chapters? -->
].
What distinguishes geocomputation from the older quantitative geography, is its emphasis on "creative and experimental" GIS applications [@longley_geocomputation:_1998].
Additionally, it is also about developing new, research-driven methods [@openshaw_geocomputation_2000]:

> GeoComputation is about using the various different types of geodata and about
developing relevant geo-tools within the overall context of a 'scientific'
approach.

But geocomputation and this book teach more than just methods and code: they are about *doing*
"practical work that is beneficial or useful" [@openshaw_geocomputation_2000].
Of course, reading this book will give you a solid *knowledge* of geocomputational methods, and how to use them via the reproducible examples implemented in the code chunks in each chapter.
But there is much more.
This book aims to teach how to do geocomputation rather than just to think about it.
Hence, you should be also able to apply the learned methods and mastered skills to real-world data, i.e. your data.
Moreover, throughout the book we encourage you to make geographic research more reproducible, scientific and socially beneficial. 
Please note that this book is also part of the movement towards Geographical Information Science (GDS) which supports the above mentioned concepts.
GSD also differs from GIS in several ways, some of which are outlined in Table \@ref(tab:gdsl).

```{r gdsl, echo=FALSE, message=FALSE}
d = readr::read_csv("extdata/gis-vs-gds-table.csv")
knitr::kable(x = d, caption = "Differences in emphasis between the fields of Geographic Information Systems (GIS) and Geographic Data Science (GDS).")
```

While embracing recent developments in the field, we also wanted to pay respects to the wider field of Geography, with its 2000 history [@roller_eratosthenes_2010], and the narrower field of *Geographic Information System* (GIS) [@neteler_open_2008].
Geography has played an important role in explaining and influencing humanity's relationship with the natural world, and this book aims to be a part of the 'Geographic tradition'.
GIS has become almost synonymous with handling spatial data on a computer, and provides a basis for excellent open source tools which can be accessed from R, as we will see in Chapter 13.

The book's links to older disciplines were reflected in suggested titles for the book: *Geography with R* and *R for GIS*.
Each has advantages.
The former conveys the message that it comprises much more than just spatial data: 
non-spatial attribute data are inevitably interwoven with geometry data, and Geography is about more than where something is on the map.
The latter communicates that this is a book about using R as a GIS, to perform spatial operations on *geographic data* [@bivand_applied_2013].
However, the term GIS conveys some connotations (see Table \@ref(tab:gdsl)) which simply fail to communicate one of R's greatest strengths:
its unparalleled console-based ability to seamlessly switch between geographic and non-geographic data processing, modeling and visualization tasks.
By contrast, the term geocomputation implies reproducible and creative programming.
Of course, (geocomputational) algorithms are powerful tools that can become highly complex.
However, all algorithms are composed of smaller parts.
By teaching you its foundations and underlying structure, we aim to empower you to create your own innovative solutions to geographic data problems.

## Why Geocomputation with R?

Early geographers used a variety of tools including rulers, compasses and sextants to advance knowledge about the world. 
However, until John Harrison invented the marine chronometer in the 18th century it had been impossible to determine the exact longitude at sea ('the longitude problem').
Prior to his invention ships followed for centuries a line of constant latitude making each journey much longer, more expensive and often also more dangerous.
Nowadays this seems unimaginable with every smarthphone having a GPS receiver at its disposal.
<!--nowadays part-->
And there are a multitude of other sensors measuring the world in real-time (satellites, radar, autonomous cars, citizens, etc.).
For instance, an autonomous car is believed to create one terrabyte of data on a daily base.
Equally, earth observation data (satellite imagery) has become so big that it is impossible to analyze the corresponding data with a single computer (see [http://r-spatial.org/2016/11/29/openeo.html](http://r-spatial.org/2016/11/29/openeo.html)).
Hence, we need computational power, software and related tools to handle and extract the most interesting patterns of this ever-increasing amount of (geo-)data.
In this book we treat R as a 'tool for the trade' when it comes to analyzing (subsets of) such data.
However, data management, storing and querying is better left to dedicated (geo-)database software.

### Advantages of R (in geospatial analysis)

R is a multi-platform, open source language for statistical computing and graphics ([https://www.r-project.org/](https://www.r-project.org/)).
This also includes advanced geostatistical and spatial modeling as well as geocomputation and mapping.
At its core R is an object-oriented, [functional programming language](http://adv-r.had.co.nz/Functional-programming.html) [@wickham_advanced_2014], and was specifically designed as an interactive interface to other software [@chambers_extending_2016]. 
The latter also includes many 'bridges' to a treasure trove of GIS software, geolibraries and functions.
<!--
todo - add this reference to end of previous line:
(\@ref(gis)).
-->
It is thus ideal for quickly creating 'geo-tools', without needing to master lower level languages (compared to R) such as C, FORTRAN and Java. 
This can feel like breaking free from the metaphorical 'glass ceiling' imposed by GUI-based proprietary geographic information systems (see Table \@ref(tab:gdsl) for a definition of GUI).
What is more, advanced users might even extend R with the power of other languages (e.g., C++ through **Rcpp** or Python through **reticulate**).
The major open-source GIS platforms (QGIS, GRASS, SAGA) are all based on C++.
Hence, you could implement geoalgorithms you are missing with the help of **Rcpp**^[Though, in that case we would recommend to contribute the C++ code to one of the open-source GIS packages since this would make the geoalgorithm available to a wider audience.
In turn, you could access the GIS software via one of the availabe R-GIS interfaces.
<!--(\@ref(gis))]-->
].

An example showing R's flexbility with regard to geographic software development is its support for generating interactive maps thanks to **leaflet** [@R-leaflet].
The packages **tmap** and **mapview** [@R-tmap; @R-mapview] are built on and extend **leaflet**.
These packages help overcome the criticism that R has "limited interactive [plotting] facilities" [@bivand_applied_2013]. 
The code below illustrates this by generating Figure \@ref(fig:interactive).

```{r, eval=FALSE, echo=FALSE}
a = osmdata::getbb("Hereford")
b = osmdata::getbb("Bialystok")
rowMeans(a)
rowMeans(b)
```

```{r interactive, fig.cap="World at night imagery from NASA overlaid by the authors' approximate home locations to illustrate interactive mapping with R."}
library(leaflet)
popup = c("Robin", "Jakub")
leaflet() %>%
  addProviderTiles("NASAGIBS.ViirsEarthAtNight2012") %>% 
  addAwesomeMarkers(lng = c(-3, 23), lat = c(52, 53), popup = popup)
```

It would be difficult to produce Figure \@ref(fig:interactive) with only four lines of code in another language, let alone embed the results in an interactive html page (the interactive version can be viewed at [robinlovelace.net/geocompr](http://robinlovelace.net/geocompr/intro.html)), illustrating R's flexibility. 
The use of R code therefore enables teaching geocomputation with reference to reproducible examples such as that provided in \@ref(fig:interactive) rather than abstract concepts.
<!-- Other reasons for using R for geocompuation include: -->

### Python, Java, C++

At the moment many people think that there is a battle raging on between R and Python for the data science throne.
We will not take part in this debate since we believe that both languages have their merits, and in the end it is about doing geocomputation and communicating the corresponding results regardless of the chosen software.
Moreover, both languages are object-oriented, and have lots of other things in common.
Learning one should give you a headstart when choosing to learn the other as well.
R's major advantage is that statisticians wrote hundreds of statistical packages (unmatched by Python) explicitly for other statisticians.
By contrast, Python's major advantage is that it is (unlike R) a multi-purpose language thereby bringing together people from diverse fields.
So if you like Python better or you think it better suits your needs, go for it.
In fact, we often advise our students to start with Python just because the major GIS software packages provide Python libraries that lets the user access its geoalgorithms from the Python command line^[`grass.script` for GRASS (https://grasswiki.osgeo.org/wiki/GRASS_and_Python), `saga-python` for SAGA-GIS (http://saga-python.readthedocs.io/en/latest/), `processing` for QGIS and `arcpy` for ArcGIS.
].
However, when the teaching moves on to statistical geoprocessing and spatial predictive modeling we refer them to R where they can take advantage of the concepts already learned through Python.

Shapely is a Python package for set-theoretic analysis and manipulation of planar features using (via Python’s ctypes module) functions from the well known and widely deployed GEOS library. GEOS, a port of the Java Topology Suite (JTS), is the geometry engine of the PostGIS spatial extension for the PostgreSQL RDBMS. The designs of JTS and GEOS are largely guided by the Open Geospatial Consortium‘s Simple Features Access Specification [1] and Shapely adheres mainly to the same set of standard classes and operations

from osgeo import ogr, gdal (-> rgdal functionality)
Python: spatial autocorrelation (PySAL) but not possible to include spatial autocorrelation structures
Python raster processing with NumPy and PyGeoProcessing
Python has adopted the ggplot2 system 
<!-- Add something with regard to Python and Java, probably the other two programming languages most often used in GIScience context -->

## R's spatial ecosystem

Before cracking-on with the action, a few introductory remarks are needed to explain the approach taken here and provide context.
<!-- paragraphs (with references to chapters in the book): -->
<!-- 1. this book focus -> sf + raster/stars + leaflet/mapview (the recent state of spatial R); the history of R spatial is way longer -->

There are many ways to handle spatial data in R, with dozens of packages in the area.^[An overview of R's spatial ecosystem can be found in the CRAN Task View on the Analysis of Spatial Data
(see [cran.r-project.org/web/views/Spatial.html](https://cran.r-project.org/web/views/Spatial.html)).]
In this book we endeavor to teach the state-of-the-art in the field whilst ensuring that the methods are future-proof.
Like many areas of software development, R's spatial ecosystem is rapidly evolving.
Because R is open source, these developments can easily build on previous work, by 'standing on the shoulders of giants', as Isaac Newton put it in [1675](http://digitallibrary.hsp.org/index.php/Detail/Object/Show/object_id/9285).
This approach is advantageous because it encourages collaboration and avoids 'reinventing the wheel'.
The package **sf** (covered in Chapter \@ref(spatial-class)), for example, builds on its predecessor **sp**.

Shifts in R's spatial ecosystem have been influenced by shifts in the wider R community, as exemplified by the visualization and data processing packages **ggplot2** and **dplyr** (released in [2007](https://cran.r-project.org/src/contrib/Archive/ggplot2/) and [2014](https://cran.r-project.org/src/contrib/Archive/dplyr/) respectively).
Alongside other packages that have a shared style and emphasis on 'tidy data', these were placed in the **tidyverse** 'metapackage' in late [2016](https://cran.r-project.org/src/contrib/Archive/tidyverse/).
The **tidyverse** approach, with its focus on long-form data and fast, intuitively named function, has become immensely popular.
This has led to demand for 'tidy spatial data' which has been partly met by **sf** and other approaches such as the GitHub package [**tabularaster**](https://hypertidy.github.io/tabularaster/).
Another feature of the **tidyverse**, which was already present in the trio of packages that **sf** supersedes (**sp**, **rgeos** and **rgdal**), is the tendency for packages to work in harmony.
Although there is presently no equivalent **geoverse**, there are a growing number of actively developed packages which are designed to work in harmony with **sf** (Table \@ref(tab:revdep)) and discussion of harmonization among R's many spatial packages.^[
See the [r-spatial](https://github.com/r-spatial/) organisation and conversations in the [discussion](https://github.com/r-spatial/discuss/issues/11) repo for more on this.
]

```{r revdep, echo=FALSE, message=FALSE}
top_dls = readr::read_csv("extdata/top_dls.csv")
knitr::kable(top_dls[1:5, 1:2], digits = 0, caption = paste0("The top 5 most downloaded packages that depend on sf, in terms of average number of downloads per day over the previous month. As of ", min(top_dls$date), " there are ", nrow(top_dls), " packages which import sf."))
# cranlogs::cran_top_downloads(when = "last-month") # most downloaded pkgs
```

A surge in development time (and interest) in 'R-Geo' has followed the award of a grant by the R Consortium for the development of support for Simple Features and the resulting **sf** package (covered in \@ref(intro-sf)).
This is illustrated in multiple places, not least the [R-sig-Geo Archives](https://stat.ethz.ch/pipermail/r-sig-geo/), a long-standing open access email list containing much R-spatial wisdom accumulated over the years.
Many posts on the list now discuss **sf** and related packages, suggesting that R's spatial software developers are using the package and, therefore, it is here to stay.

We propose that the release of **sf** heralds a new era for spatial data analysis and geocomputation in R.
This era (which we refrain from labeling the **geoverse** with any seriousness, awaiting a better name!) clearly has the wind in its sails and is set to dominate future developments in R's spatial ecosystem for years to come.
So time invested in learning the 'new ways' of handling spatial data and, hopefully, reading this book, is well spent!

```{r cranlogs, fig.cap="The popularity of spatial packages in R. The y-axis shows the average number of downloads, within a 30-day rolling window, of R's top 5 spatial packages, defined as those with the highest number of downloads within the last 30 days.", echo=FALSE}
knitr::include_graphics("figures/spatial-package-growth.png")
```

## R's spatial history

There are many benefits of using recent packages such as **sf**, with the caveat that they are generally less stable than mature packages such as **sp**.
This is captured by the saying "if you live on the cutting edge you risk getting hurt", meaning that older packages may be more appropriate for applications requiring stability and backwards-compatibility with other mature packages.
Another reason for knowing about the history of geocomputation with R is that there is a wealth of functions, use-cases and teaching material written using older packages in R's spatial ecosystem, which can still be useful today provided you know where to look.

The beginnings of spatial capabilities in R are closely connected with its predecessor - the S language [@bivand_implementing_2000].
The 1990s saw the development of numerous S scripts and a handful of packages for spatial statistics.
Some of these, including **spatial**, **sgeostat** and **splancs**,  eventually became R packages [@rowlingson_splancs:_1993; @rowlingson_splancs:_2017;@venables_modern_2002; @university_sgeostat:_2016].

Volume 1/2 of R News (the predecessor of The R Journal) contained an overview of spatial statistical software in R at the time, much of which was based on previous code written for S/S-PLUS [@ripley_spatial_2001].
This overview described packages for spatial smoothing and interpolation (e.g. **akima**, **spatial**, **sgeostat** and **geoR**) and point pattern analysis (**splancs** and **spatstat**) [@akima_akima:_2016; @rowlingson_splancs:_2017; @jr_geor:_2016].
While all these are still available on CRAN, **spatstat** stands out among them, as it remains dominant in the field of spatial point pattern analysis [@baddeley_spatial_2015].

The subsequent issue of R News also put spatial packages in the spotlight, with an introduction **splancs** and commentary on future prospects [@bivand_more_2001].
Notably, the paper mentions the need for standardization of spatial interfaces, efficient mechanisms for exchanging data with GIS, and handling of spatial metadata such as coordinate reference systems (CRS).
Two years later an extended review of spatial packages was published [@hornik_approaches_2003]. 
Around this time the development of R's spatial capabilities started to be augmented with links to external libraries, especially GDAL) and PROJ.4, which facilitate geographic data I/O (covered in chapter \@ref(read-write)) CRS transformations respectively.
Based on the wide range of data formats that could be read-in by GDAL, @hornik_approaches_2003 also proposed a spatial data class system, including support for points, lines, polygons and grids.
These ideas can be seen in **rgdal** and **sp**, which became foundational packages for spatial data analysis with R [@bivand_applied_2013].

**rgdal**, first released in 2003, greatly extended R's spatial capabilities in terms of access to spatial data formats previously unavailable to R users.
Importantly, it enabled storing information about coordinate reference system and allowed for map projection and datum transformation.
**sp**, released in 2005, overcame R's inability to distinguish spatial and non-spatial objects.
Prior to 2005, spatial coordinates were generally were treated as any other number. 
**sp** provided generic classes and methods for spatial data.
The sophisticated class system supported points, lines, polygons and grids, with and without attribute data. 

<!--???-->
<!-- points, multipoints, pixels, full grid, line, lines, spatial lines, polygon, polygons, spatial polygons -->
**sp** used the S4 class system, which allowed each piece of 'spatially specific' information (such as bounding box, coordinate reference system, attribute table) to stored in slots, accessed with the `@` symbol.
Attribute data in **sp** were stored as a `data.frame` in the `@data` slot, enabling non-spatial data operations to work alongside spatial operations (covered in chapters \@ref(attr) and \@ref(spatial-data-operations) respectively).
**sp** implemented generic methods for spatial data, making functions well-known to R users such as `summary()` and `plot()` work seamlessly with a wide range of spatial data types.
Spatial information such as bounding box and CRS could also be retrieved by **sp** functions.
<!-- The **sp** package together with **rgdal** made possible transformations between coordinate reference systems and provided mapping capabilities using either the base plotting system or the lattice system. -->

**sp** classes rapidly became the go-to standard for spatial data in R, resulting in a proliferation of packages that depended on it from around 20 in 2008 and over 100 in 2013 [@bivand_applied_2013].
Now more than 200 packages rely on **sp**, making it an important part of the R ecosystem. 
<!-- https://github.com/Robinlovelace/geocompr/issues/58 -->
<!-- https://github.com/edzer/sfr/issues/387#issuecomment-308949140 -->

Prominent R packages using **sp** include: **gstat**, for spatial and spatio-temporal geostatistics; **geosphere**, for spherical trigonometry; and **adehabitat** used for the analysis of habitat selection by animals [@R-gstat; @calenge_package_2006; @hijmans_geosphere:_2016].

While **rgdal** and **sp** solved many spatial issues, R still lacked a geometry calculation abilities.
This issue was resolved in 2010 with the release of **rgeos** package [@R-rgeos], which allowed functions and operators from the GEOS library to manipulate **sp** objects.
**sp**'s limited support of raster data was also tackled in 2010, with the creation of the **raster** [@R-raster], which defined the `raster` class and provided functions for creating, reading and writing raster data.
A key feature of **raster** is its ability to work with datasets too large to be fitted in RAM, increasing the scale of spatial datasets R could handle.^[The
**raster** package also provided tools for raster algebra, general raster functions and the development of more additional raster functions.]

In parallel with the development of spatial classes and methods came support for R to be used as an interface to dedicated GIS software.
The **GRASS** package [@bivand_using_2000] and follow-on packages **spgrass6** and **rgrass7** (for GRASS GIS 6 and 7 respectively) were prominent examples in this direction [@bivand_spgrass6:_2016;@bivand_rgrass7:_2016].
Other examples of bridges between R and GIS included **RSAGA** [@R-RSAGA, first published 2008], **ArcGIS** [@brenning_arcgis_2012, first publish 2008], and **RQGIS** [@R-RQGIS, first published 2016].
<!-- ADD THIS LATTER -->
<!-- More information about interfaces between R and GIS software could be find in \@ref(gis). -->

Map making was not a focus of R's early spatial capabilities.
Although **sp** provided methods for plotting using base and lattice systems, demand for alternatives was growing in the 2000s, especially with the publication of **ggplot2** in 2007.
**ggplot2**'s spatial capabilities were improved in 2011 with the release of **ggmap**, which provided several tools for spatial data visualization [@kahle_ggmap:_2013].
**ggmap** provided support for base maps with Google Maps or OpenStreetMap and spatial APIs such as Google's Geocoding service.
In the next year, raster visualization methods received a boost with the release of **rasterVis** [@lamigueiro_displaying_2014]. 

More recently, packages have been developed with the aim of easing the creation of complex, publication-quality maps with minimal code.
The **tmap** package (released in 2014) is the archetype in this area [@R-tmap] and facilitates the user-friendly creation of thematic maps with an intuitive command-line interface  (also see [**mapmisc**](https://cran.r-project.org/package=mapmisc)) . 
<!-- ADD THIS LATTER -->
<!-- CITE the paper Tennekes, M. (2017) tmap: Thematic Maps in R. Forthcoming in the Journal
of Statistical Software http://von-tijn.nl/tijn/research/presentations/tmap_user2017.pdf-->
**tmap** provides legends, scale bars, grid lines, north arrows, optimized for mapping and integrates with the **leaflet** package (released in 2015) to offer interactive maps [@R-leaflet]. 
Additionally, the **mapview** package was created on top of **leaflet** [@R-mapview], enabling interactive maps to be created rapidly from **sp** or **sf** objects using a range of background maps, scale bars and more.

Among all this development, most important recent evolution in R's spatial ecosystem has without doubt been support for simple features thanks to the **sf** package [@R-sf], described in Chapter \@ref(spatial-class).

<!-- ## How to read this book -->

## Exercises

1. Think about the terms 'GIS', 'GDS' and 'Geocomputation' described above. Which is your favorite and and why?

1. Provide 3 reasons for using a scriptable language such as R for geocomputation instead of using an established GIS programs such as QGIS.

1. Name two advantages and two disadvantages of using the older **sp** package compared with the new **sf** package.

